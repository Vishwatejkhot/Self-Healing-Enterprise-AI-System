
# ğŸ›¡ï¸ AegisAI â€“ Self-Healing Enterprise AI System

AegisAI is a **self-healing Retrieval-Augmented Generation (RAG) system** built for enterprise use.  
It answers questions strictly from internal documents, detects uncertainty or failures, and automatically repairs itself **without blocking the user experience**.

This project demonstrates **production-grade AI engineering**, focusing on reliability, safety, and observability rather than just chatbot responses.

---

## ğŸ” What Problem Does AegisAI Solve?

In real companies:
- Internal documents are large and fragmented
- Employees ask repetitive questions
- AI systems hallucinate answers
- Wrong answers can cause serious business risk

**AegisAI solves this by:**
- Answering only from internal documents
- Refusing to hallucinate
- Measuring retrieval confidence
- Detecting failures
- Automatically self-healing when issues occur

---

## âœ¨ Key Features

- âœ… Retrieval-Augmented Generation (RAG)
- âœ… Vector search using FAISS
- âœ… Confidence-aware answers
- âœ… Hallucination detection
- âœ… Non-blocking self-healing loop
- âœ… Policy and safety enforcement
- âœ… Audit logging and monitoring
- âœ… Modern Flask-based UI
- âœ… API + UI support
- âœ… Groq-hosted LLMs (LLaMA / GPT-OSS)

---

## ğŸ§  High-Level Architecture

1. User asks a question (UI or API)
2. Relevant document chunks are retrieved from the vector store
3. LLM generates an answer using retrieved context only
4. System evaluates:
   - Answer quality
   - Retrieval confidence
   - Policy compliance
5. If uncertainty is detected:
   - Answer is still returned
   - System self-heals in the background

---

## ğŸ“ Project Structure

```
AegisAI/
â”œâ”€â”€ app.py                 # Flask app (UI + API orchestration)
â”œâ”€â”€ config.py              # Central configuration
â”œâ”€â”€ data/                  # Raw internal documents (source of truth)
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ ingest.py          # Loads & chunks documents
â”‚   â””â”€â”€ fingerprint.py     # Detects document changes
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ vectorstore.py     # FAISS vector database
â”‚   â””â”€â”€ retriever.py       # Context retrieval + confidence scoring
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ answer_agent.py    # Generates grounded answers
â”‚   â”œâ”€â”€ critic_agent.py    # Detects hallucinations / failures
â”‚   â”œâ”€â”€ policy_agent.py    # Safety & policy enforcement
â”‚   â””â”€â”€ root_cause_agent.py# Failure diagnosis
â”‚
â”œâ”€â”€ healing/
â”‚   â”œâ”€â”€ self_heal.py       # Automatic system repair
â”‚   â””â”€â”€ prompt_repair.py   # Prompt improvement
â”‚
â”œâ”€â”€ evals/
â”‚   â”œâ”€â”€ groundedness.py    # Answer grounding checks
â”‚   â””â”€â”€ regression.py     # Regression testing
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ metrics.py         # Query & failure metrics
â”‚   â””â”€â”€ audit_log.py       # Compliance & audit logs
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ inject_failures.py # Failure simulation
â”‚
â”œâ”€â”€ vectorstore/           # Generated FAISS index (rebuildable)
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸ–¥ï¸ Running the Project Locally

### 1ï¸âƒ£ Create virtual environment
```bash
uv init
uv venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies
```bash
uv add -r requirements.txt
```

### 3ï¸âƒ£ Add your Groq API key
Create a `.env` file:
```
GROQ_API_KEY=your_groq_api_key_here
```

---

### 4ï¸âƒ£ Ingest documents
```bash
python -m ingestion.ingest
```

---

### 5ï¸âƒ£ Run the application
```bash
python app.py
```

Open in browser:
```
http://127.0.0.1:5000
```

---

## ğŸ“Š Confidence & Self-Healing

- High confidence â†’ normal response
- Medium confidence â†’ response + monitoring
- Low confidence â†’ response + background self-healing

---



## ğŸ“œ License

MIT License

---

## ğŸ™Œ Author

Vishwatej Khot
